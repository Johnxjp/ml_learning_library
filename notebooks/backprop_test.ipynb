{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw.network import LinearANN\n",
    "from raw.losses import binary_cross_entropy, d_binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_layers = [5]\n",
    "output_size = 2\n",
    "model = LinearANN(input_size, hidden_layers, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearANN {\n",
       "  Linear - weights: (10, 5), bias: (5,)\n",
       "  Linear - weights: (5, 2), bias: (2,)\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(positive_class_inds, batch_size, output_size):\n",
    "    y = np.zeros((batch_size, output_size), dtype=np.float)\n",
    "    y[np.arange(len(y)), positive_class_inds] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "x = np.random.normal(size=(batch_size, input_size))\n",
    "y = np.random.randint(0, 2, size=(batch_size,))\n",
    "print(y)\n",
    "y = one_hot(y, batch_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0.]]),\n",
       " array([[-0.81684848, -0.05829526, -1.5175493 ,  0.9165314 , -1.85453004,\n",
       "         -0.85769108, -0.4260255 ,  0.15387974,  0.73615067,  0.07140471]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_batch = binary_cross_entropy(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54023501, 1.55101486]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss 2.091249868213781\n"
     ]
    }
   ],
   "source": [
    "batch_loss = np.mean(np.sum(loss_per_batch, -1))\n",
    "print(\"Batch loss\", batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_error = d_binary_cross_entropy(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.71641019,  4.71625408]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sense check. Remember if the loss error is negative then it means increasing the activation value will send the loss down and decreasing will increase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.58261132, 0.78796732]]), array([[1., 0.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward(loss_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58615781 0.78262758]] [[1. 0.]]\n",
      "[[0.62058667 0.72485851]] [[1. 0.]]\n",
      "[[0.65056077 0.66384735]] [[1. 0.]]\n",
      "[[0.67670358 0.60285526]] [[1. 0.]]\n",
      "[[0.69958996 0.54466162]] [[1. 0.]]\n",
      "[[0.71971955 0.49112891]] [[1. 0.]]\n",
      "[[0.73751468 0.44316483]] [[1. 0.]]\n",
      "[[0.75332831 0.40093292]] [[1. 0.]]\n",
      "[[0.76745417 0.36412859]] [[1. 0.]]\n",
      "[[0.78013648 0.33221173]] [[1. 0.]]\n",
      "[[0.79157838 0.30456362]] [[1. 0.]]\n",
      "[[0.80194901 0.28057704]] [[1. 0.]]\n",
      "[[0.81138957 0.25970008]] [[1. 0.]]\n",
      "[[0.82001826 0.24145201]] [[1. 0.]]\n",
      "[[0.82793449 0.22542426]] [[1. 0.]]\n",
      "[[0.83522224 0.21127436]] [[1. 0.]]\n",
      "[[0.84195281 0.19871738]] [[1. 0.]]\n",
      "[[0.8481871  0.18751691]] [[1. 0.]]\n",
      "[[0.8539774  0.17747685]] [[1. 0.]]\n",
      "[[0.85936884 0.16843427]] [[1. 0.]]\n",
      "[[0.86440062 0.16025337]] [[1. 0.]]\n",
      "[[0.86910689 0.15282058]] [[1. 0.]]\n",
      "[[0.87351763 0.14604045]] [[1. 0.]]\n",
      "[[0.87765919 0.13983249]] [[1. 0.]]\n",
      "[[0.88155491 0.1341284 ]] [[1. 0.]]\n",
      "[[0.88522549 0.12887003]] [[1. 0.]]\n",
      "[[0.88868936 0.12400763]] [[1. 0.]]\n",
      "[[0.89196303 0.11949839]] [[1. 0.]]\n",
      "[[0.89506129 0.11530536]] [[1. 0.]]\n",
      "[[0.89799744 0.1113965 ]] [[1. 0.]]\n",
      "[[0.9007835  0.10774387]] [[1. 0.]]\n",
      "[[0.90343032 0.10432307]] [[1. 0.]]\n",
      "[[0.90594777 0.10111265]] [[1. 0.]]\n",
      "[[0.9083448  0.09809373]] [[1. 0.]]\n",
      "[[0.91062957 0.09524961]] [[1. 0.]]\n",
      "[[0.91280953 0.09256545]] [[1. 0.]]\n",
      "[[0.9148915  0.09002807]] [[1. 0.]]\n",
      "[[0.91688173 0.08762567]] [[1. 0.]]\n",
      "[[0.91878595 0.08534771]] [[1. 0.]]\n",
      "[[0.92060945 0.08318468]] [[1. 0.]]\n",
      "[[0.92235708 0.08112807]] [[1. 0.]]\n",
      "[[0.92403333 0.07917014]] [[1. 0.]]\n",
      "[[0.92564235 0.07730393]] [[1. 0.]]\n",
      "[[0.92718798 0.07552308]] [[1. 0.]]\n",
      "[[0.92867377 0.07382185]] [[1. 0.]]\n",
      "[[0.93010303 0.07219496]] [[1. 0.]]\n",
      "[[0.93147882 0.07063763]] [[1. 0.]]\n",
      "[[0.932804   0.06914545]] [[1. 0.]]\n",
      "[[0.93408123 0.06771441]] [[1. 0.]]\n",
      "[[0.93531298 0.06634079]] [[1. 0.]]\n",
      "[[0.93650158 0.0650212 ]] [[1. 0.]]\n",
      "[[0.93764918 0.06375248]] [[1. 0.]]\n",
      "[[0.93875781 0.06253175]] [[1. 0.]]\n",
      "[[0.93982937 0.06135631]] [[1. 0.]]\n",
      "[[0.94086563 0.06022367]] [[1. 0.]]\n",
      "[[0.94186827 0.05913155]] [[1. 0.]]\n",
      "[[0.94283884 0.05807778]] [[1. 0.]]\n",
      "[[0.94377882 0.05706038]] [[1. 0.]]\n",
      "[[0.94468959 0.05607749]] [[1. 0.]]\n",
      "[[0.94557247 0.05512737]] [[1. 0.]]\n",
      "[[0.94642868 0.05420842]] [[1. 0.]]\n",
      "[[0.94725937 0.05331912]] [[1. 0.]]\n",
      "[[0.94806565 0.05245806]] [[1. 0.]]\n",
      "[[0.94884855 0.0516239 ]] [[1. 0.]]\n",
      "[[0.94960905 0.0508154 ]] [[1. 0.]]\n",
      "[[0.95034807 0.05003141]] [[1. 0.]]\n",
      "[[0.95106649 0.04927081]] [[1. 0.]]\n",
      "[[0.95176513 0.04853257]] [[1. 0.]]\n",
      "[[0.95244479 0.04781573]] [[1. 0.]]\n",
      "[[0.95310621 0.04711936]] [[1. 0.]]\n",
      "[[0.9537501 0.0464426]] [[1. 0.]]\n",
      "[[0.95437712 0.04578464]] [[1. 0.]]\n",
      "[[0.95498793 0.0451447 ]] [[1. 0.]]\n",
      "[[0.95558312 0.04452204]] [[1. 0.]]\n",
      "[[0.95616328 0.04391599]] [[1. 0.]]\n",
      "[[0.95672895 0.04332589]] [[1. 0.]]\n",
      "[[0.95728067 0.0427511 ]] [[1. 0.]]\n",
      "[[0.95781892 0.04219106]] [[1. 0.]]\n",
      "[[0.9583442  0.04164519]] [[1. 0.]]\n",
      "[[0.95885694 0.04111297]] [[1. 0.]]\n",
      "[[0.95935759 0.04059389]] [[1. 0.]]\n",
      "[[0.95984657 0.04008748]] [[1. 0.]]\n",
      "[[0.96032426 0.03959327]] [[1. 0.]]\n",
      "[[0.96079104 0.03911083]] [[1. 0.]]\n",
      "[[0.96124729 0.03863974]] [[1. 0.]]\n",
      "[[0.96169333 0.03817962]] [[1. 0.]]\n",
      "[[0.96212952 0.03773008]] [[1. 0.]]\n",
      "[[0.96255616 0.03729076]] [[1. 0.]]\n",
      "[[0.96297356 0.03686132]] [[1. 0.]]\n",
      "[[0.963382   0.03644144]] [[1. 0.]]\n",
      "[[0.96378178 0.03603079]] [[1. 0.]]\n",
      "[[0.96417316 0.03562907]] [[1. 0.]]\n",
      "[[0.96455639 0.03523601]] [[1. 0.]]\n",
      "[[0.96493173 0.03485131]] [[1. 0.]]\n",
      "[[0.96529941 0.03447473]] [[1. 0.]]\n",
      "[[0.96565966 0.03410601]] [[1. 0.]]\n",
      "[[0.9660127 0.0337449]] [[1. 0.]]\n",
      "[[0.96635873 0.03339117]] [[1. 0.]]\n",
      "[[0.96669797 0.0330446 ]] [[1. 0.]]\n",
      "[[0.96703061 0.03270497]] [[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    out = model(x)\n",
    "    print(out, y)\n",
    "    loss_per_batch = binary_cross_entropy(out, y)\n",
    "    batch_loss = np.mean(np.sum(loss_per_batch, -1))\n",
    "    loss_error = d_binary_cross_entropy(out, y)\n",
    "    model.backward(loss_error, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
